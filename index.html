
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Skand Vishwanath Peri</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>

  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <script type="text/javascript" src="js/hidebib.js"></script>
          <name>Skand Vishwanath Peri</name><br>
          <b>Email</b>:
          <font id="email" style="display:inline;">
            <noscript><i>Please enable Javascript to view</i></noscript>
          </font>
          <script>
          emailScramble = new scrambledString(document.getElementById('email'),
              'emailScramble', 'ngspk.ioalcdm@vam',
              [6, 9, 3, 1, 4, 14, 12, 16, 5, 13, 15, 7, 10, 8, 2, 11, 17]);
    </script>
        </p>
        <p>I am a final year undergraduate studying in Computer Science at <a href="http://www.iitrpr.ac.in/">Indian Institute of Technology, Ropar, India</a>.
        </p>
        <p>
          I completed my B.Tech Thesis in the field of Heterogenous Face Recognition and was guided by <a href="http://cse.iitrpr.ac.in/ckn/index.html" target="_blank">Dr. C.K. Narayanan</a>.
          I also interned at <a href="http://val.serc.iisc.ernet.in/valweb/" target="_blank">Video Analytics Lab, IISc Bangalore</a> under <a href="http://www.serc.iisc.ernet.in/~venky/" target="_blank">Dr. R.Venkatesh Babu</a> during Summer 2017 and worked on HDR Deghosting.
        </p>

        <p align=center>

          <a href="cv/cv.pdf" &nbsp/&nbsp>CV</a> &nbsp/&nbsp
          <a href="http://www.github.com/pvskand" target="_blank"> Github </a>&nbsp/&nbsp
          <a href="http://www.twitter.com/pvskand" target="_blank"> Twitter </a>&nbsp/&nbsp
          <a href="http://www.linkedin.com/in/pvskand" target="_blank"> Linkedin </a>&nbsp/&nbsp
          <a href="https://scholar.google.co.in/citations?user=AaY4U-wAAAAJ&hl=en" target="_blank"> Google Scholar </a>
        </p>
        </td>
        <td width="33%">
        <img src="images/skand-circle.png" width="100%">
        </td>
      </tr>
      </table>

      <!-- NEWS -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr><td>
          <heading>News</heading>
          <ul>
            <li> [July, 2018] - <a href="#MICCAI18">Paper</a> on MRI to FDG-PET: Cross-Modal Synthesis Using 3D U-Net For Multi-Modal Alzheimer's Classification accepted at <a target="_blank" href="https://www.miccai2018.org"> MICCAI </a> Workshop on <a target="_blank" href="http://www.sashimi.aramislab.fr/"> Simulation and Synthesis in Medical Imaging, 2018. </a>  </li>
            <li> [July, 2018] - <a href="#ACMMM18">Paper</a> on Deep Cross modal learning for Caricature Verification and Identification accepted at <a href="http://acmmm.org/">ACM Multimedia(MM), 2018.</a></li>
            <li> [April, 2018] - <a href="#CVPRW18">Paper</a> on Disguised Face Verification in the Wild accepted at CVPRW on <a href="http://iab-rubric.org/DFW/dfw.html"> Disguised Faces in the Wild, 2018. </a>  </li>
          </ul>
        </td></tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
          I'm interested in Computer Vision, Machine Learning, Computational Photography, HDR Imaging, Image Registration, Cross-Modality generative models, Heterogenous Face Verification & Identification. I have recently been exposed to cognitive science and neuro sciences and I am enjoying it a lot.
          </p>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Affiliations</heading>

          <p>
          <a href="http://iitrpr.ac.in"><img src="images/iitrprlogo.jpg" width="100" hspace="50"> </a>
          <a href="http://iisc.ac.in/"><img src="images/iisc.jpg" width="100" hspace="50"> </a>
          <a href="http://val.serc.iisc.ernet.in/valweb/"><img src="images/val.jpg" width="100" hspace="50"> </a>
          </p>
        </td>
      </tr>
      </table>




      <!-- PUBLICATIONS -->


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr><td><heading>Publications</heading></td></tr>
        </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

            <tr>
              <td width="33%" valign="top" align="center"><img src="images/miccai18.png" style="border-color:black" width="220" height="150"><hr style="height:0pt; visibility:hidden; margin:0"/>
              <td width="67%" valign="top">
                <p id="MICCAI18">
                <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none">
                <heading style="color:#1772d0;"> MRI to FDG-PET: Cross-Modal Synthesis Using 3D U-Net For Multi-Modal Alzheimer's Classification</heading></a><br>
                Apoorva Sikka*, <strong>Skand Vishwanath Peri</strong>*, Deepti.R.Bathula<br>
                <em>In MICCAI Workshop on Simulation and Synthesis in Medical Imaging</em>, 2018 (to appear)<br>
                <!-- <strong style="color:red">Oral presentation <a href="https://vimeo.com/237270588" target="_blank" style="color:red">[video]</a></strong> -->
                <!-- <strong style="color:red">Oral presentation</strong> -->
                </p>

                <div class="paper" id="miccai18">
                <a href="javascript:toggleblock('miccai_abs')">abstract</a> |
                <a shape="rect" href="javascript:togglebib('miccai18')" class="togglebib">bibtex</a> |
                <a href="https://arxiv.org/abs/1807.10111" target="_blank">arXiv</a>
                <br>

                <p align="justify"> <i id="miccai_abs"> Recent studies suggest that combined analysis of Magnetic resonance imaging~(MRI) that measures brain atrophy and positron emission tomography~(PET) that quantifies hypo-metabolism provides improved accuracy in diagnosing Alzheimer's disease. However, such techniques are limited by the availability of corresponding scans of each modality. Current work focuses on a cross-modal approach to estimate FDG-PET scans for the given MR scans using a 3D U-Net architecture. The use of the complete MR image instead of a local patch based approach helps in capturing non-local and non-linear correlations between MRI and PET modalities. The quality of the estimated PET scans is measured using quantitative metrics such as MAE, PSNR and SSIM. The efficacy of the proposed method is evaluated in the context of Alzheimer's disease classification. The accuracy using only MRI is 70.18% while joint classification using synthesized PET and MRI is 74.43% with a p-value of 0.06. The significant improvement in diagnosis demonstrates the utility of the synthesized PET scans for multi-modal analysis.
                </i></p>


                <pre xml:space="preserve">
                @inproceedings{MRI2PET_MICCAI,
                    Author = {Sikka, Apoorva and Peri, Skand Vishwanath and Bathula, Deepti.R},
                    Title = { MRI to FDG-PET: Cross-Modal Synthesis Using 3D U-Net For Multi-Modal Alzheimer's Classification},
                    Booktitle = {MICCAI Workshop on Simulation and Synthesis in Medical Imaging},
                    Year = {2018}
                }
                </pre>
                </div>
              </td>
            </tr>

            <tr>
              <td width="33%" valign="top" align="center"><img src="images/cavinet.jpg" style="border-color:black" width="220" height="150"><hr style="height:0pt; visibility:hidden; margin:0"/>
              <td width="67%" valign="top">
                <p id="ACMMM18">
                <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none">
                <heading style="color:#1772d0;">Deep Cross modal learning for Caricature Verification and Identification (CaVINet)</heading></a><br>
                Jatin Garg*, <strong>Skand Vishwanath Peri*</strong>, Himanshu Tolani*, Narayanan.C.Krishnan<br>
                <em>ACM Multimedia</em>, 2018 (to appear)<br>
                <!-- <strong style="color:red">Oral presentation <a href="https://vimeo.com/237270588" target="_blank" style="color:red">[video]</a></strong> -->
                <!-- <strong style="color:red">Oral presentation</strong> -->
                </p>

                <div class="paper" id="acmmm18">
                <a href="javascript:toggleblock('acmmm18_abs')">abstract</a> |
                <a shape="rect" href="javascript:togglebib('acmmm18')" class="togglebib">bibtex</a> |
                <a href="https://arxiv.org/abs/1807.11688" target="_blank">arXiv</a> |
                <a href="https://lsaiml.github.io/CaVINet/" target="_blank">project page </a>
                <br>

                <p align="justify"> <i id="acmmm18_abs"> Learning from different modalities is a challenging task that involves determining a shared space that bridges the two modalities. In this paper, we look at the challenging problem of cross modal face verification and recognition between caricature and visual image modalities. Caricature is a modality with images having exaggerations of facial features of a person. Due to the significant variations in the caricatures, building vision models for recognizing and verifying data from this modality is an extremely challenging task. Visual images with significantly lesser amount of distortions can act as a bridge for the analysis of caricature modality. To advance the research in this field, we have created a publicly available large Caricature-VIsual dataset [CaVI] with images from both the modalities. The dataset captures the rich variations in the caricature of an identity. This paper presents the first cross modal architecture that is able to handle extreme distortions present in caricatures using a deep learning network that learns similar representations across the modalities. We use two convolutional networks along with transformations that are subjected to orthogonality constraints to capture the shared and modality specific representations. In contrast to prior research, our approach neither depends on manually extracted facial landmarks for learning the representations, nor on the identities of the person for performing verification. The learned shared representation achieves 91% accuracy for verifying unseen images and 75% accuracy on unseen identities. Further, recognizing the identity in the image by knowledge transfer using a combination of shared and modality specific representations, resulted in an unprecedented performance of 85% rank-1 accuracy for caricatures and 95% rank-1 accuracy for visual images.
                 </i></p>


                <pre xml:space="preserve">
                @inproceedings{CaVINet_ACMMM18,
                    Author = {Garg, Jatin and Peri, Skand Vishwanath and Tolani, Himanshu and
                    Krishnan, Narayana.C},
                    Title = {Deep Cross modal learning for Caricature Verification and Identification (CaVINet)},
                    Booktitle = {ACM Multimedia},
                    Year = {2018}
                }
                </pre>
                </div>
              </td>
            </tr>

            <tr>
              <td width="33%" valign="top" align="center"><img src="images/disguisenet.jpg" style="border-color:black" width="220" height="150"><hr style="height:0pt; visibility:hidden; margin:0"/>
              <td width="67%" valign="top">
                <p id="CVPRW18">
                <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none">
                <heading style="color:#1772d0;">DisguiseNet : A Contrastive Approach for Disguised Face Verification in the Wild</heading></a><br>
                <strong>Skand Vishwanath Peri</strong>, Abhinav Dhall<br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition, Workshop on Disguised Faces in the Wild (CVPRW)</em>, 2018<br>
                <!-- <strong style="color:red">Oral presentation <a href="https://vimeo.com/237270588" target="_blank" style="color:red">[video]</a></strong> -->
                <!-- <strong style="color:red">Oral presentation</strong> -->
                </p>

                <div class="paper" id="cvprw18">
                <a href="javascript:toggleblock('cvprw18_abs')">abstract</a> |
                <a shape="rect" href="javascript:togglebib('cvprw18')" class="togglebib">bibtex</a> |
                <a href="https://arxiv.org/abs/1804.09669" target="_blank">arXiv</a>
                <br>

                <p align="justify"> <i id="cvprw18_abs">This paper describes our approach for the Disguised Faces in the Wild (DFW) 2018 challenge. The task here is to verify the identity of a person among disguised and impostors images. Given the importance of the task of face verification it is essential to compare methods across a common platform. Our approach is based on VGG-face architecture paired with Contrastive loss based on cosine distance metric. For augmenting the data set, we source more data from the internet. The experiments show the effectiveness of the approach on the DFW data. We show that adding extra data to the DFW dataset with noisy labels also helps in increasing the generalization performance of the network. The proposed network achieves 27.13% absolute increase in accuracy over the DFW baseline.</i></p>

                <pre xml:space="preserve">
                @inproceedings{periCVPRW,
                    Author = {Peri, Skand V. and
                    Dhall, Abhinav},
                    Title = {DisguiseNet : A Contrastive Approach for Disguised Face Verification in the Wild},
                    Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
                    Year = {2018}
                }
                </pre>
                </div>
              </td>
            </tr>

      </table>
      <h3 style="color:#1772d0;"> &ensp; &ensp; * - Denotes Equal Contribution </h3>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Internships</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>

        <td width="75%" valign="top">
        <p>

          <papertitle>HDR Deghosting</papertitle>  (Summer 2017)

          <br>
          Mentor : <a href="http://www.serc.iisc.ernet.in/~venky/">Dr R.Venkatesh Babu</a>, Dept. of Computational and Data Sciences, IISc Bangalore, India
        <p>
          My work at IISc was focussed mainly on generating Deghosted High Dynamic Range images. I spent the initial half of my internship on segmenting moving objects in varying illumination images and the rest half was spent on registering images under high illumination variance.

        </p>
        </p>
        </td>
      </tr>
      <tr>

        <td width="75%" valign="top">
        <p>
          <a href="https://pvskand.github.io/Visualizations">
          <papertitle>Mathematical Visual Simulators</papertitle> </a> (Summer 2016)


          <br>
          Mentor : <a href="http://cse.iitrpr.ac.in/ckn/home.html">Dr C.K.Narayanan</a>, Dept. of CS, IIT Ropar
        <p>
          Developed a GUI version of <a hred="http://cse.iitrpr.ac.in/ckn/Resources/math-viz/svd.html"> Singular Value Decomposition</a>, <a href="http://cse.iitrpr.ac.in/ckn/Resources/math-viz/gradient.html">Gradient Descent</a> and <a href="http://cse.iitrpr.ac.in/ckn/Resources/math-viz/lagrange.html">Lagrange Multipliers</a> depicting their geometrical interpretation. Chart.js, Plotly.js, Numeric.js and Algebra.js libraries were used to develop the tool.

        </p>
        </p>
        </td>
      </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Course Projects</heading>
        </td>
      </tr>
      </table>
      <table  width="100%" align="center" border="0" cellpadding="20">
      <h3>Bio Medical Image Processing</h3>
        <tr>

        <td width="75%" valign="top">
        <p>

          <papertitle>Alzhemizer's Classification using MRI and PET images</papertitle>  (November, 2017) <i> [Course Final Project]</i>

          <br>
          Mentor : <a href="http://www.iitrpr.ac.in/cse/bathula">Dr. Deepti.R.Bhatula </a>, Dept. of CS, IIT Ropar, India
        <p>
          In this project a localised deep neural net based architecture with 3D Convolution to predict if the has Alzhemizer's Disease  using  PET/MRI scans of the person's brain was proposed. [ Code will be made public once the corresponding paper is published. ]
        </p>
        </p>
        </td>
      </tr>

      <tr>

        <td width="75%" valign="top">
        <p>

          <papertitle><a href="https://github.com/pvskand/NLMeansSpeckleFilter"> Nonlocal Means-Based Speckle Filtering for Ultrasound Images</papertitle>  </a>(September, 2017)

          <br>
          Mentor : <a href="http://www.iitrpr.ac.in/cse/bathula">Dr. Deepti.R.Bhatula </a>, Dept. of CS, IIT Ropar, India
        <p>
          In this project I implemented non local means based noise filtering for ultrasound images. This algorithm is specific to ultrasound speckle noise. The paper proposed a new similarity metric : Pearson Distance. A detailed information of the implementation is present in the <a href="pdf/nonlocal-speckle.pdf">report</a>.
        </p>
        </p>
        </td>
      </tr>

      <tr>

        <td width="75%" valign="top">
        <p>

          <papertitle><a href="https://github.com/pvskand/CTReconstruction">CT Reconstruction Algorithms - ART, SART, Back Projection and Filtered Back Projection></a></papertitle>  (October, 2017)

          <br>
          Mentor : <a href="http://www.iitrpr.ac.in/cse/bathula">Dr. Deepti.R.Bhatula </a>, Dept. of CS, IIT Ropar, India
        <p>
          In this work, I have implemented different Computed Tomography (CT) reconstruction algorithms. Majorly CT reconstructions involve 2 methods, Algebraic Reconstruction Algorithms and Back Projection Algorithms. I have implemented 2 variants of the first one [ART and SART] and 3 variants of the second one [simple BP and Filtered BP, Noise Filtered BP].
        </p>
        </p>
        </td>
      </tr>

      <tr>
      </table>

      <table  width="100%" align="center" border="0" cellpadding="20">
      <h3>Computer Vision</h3>

        <td width="75%" valign="top">
        <p>

          <papertitle>Personality Assessment from Videos</papertitle>  (November, 2017) <i> [Course Final Project]</i>

          <br>
          Mentor : <a href="https://sites.google.com/site/dhallabhinav/">Dr. Abhinav Dhall </a>, Dept. of CS, IIT Ropar, India
        <p>
          The main aim of this project was to assess the <strong><a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits">Big 5 personality traits</a></strong> from videos. We came up with a novel approach in which we could regress the 5 traits using the background as well as the facial features. More information about the methodology can be found <a href="pdf/big5.pdf"> here </a>.
          [Code will be published once the corresponding paper gets accepted.]

        </p>
        </p>
        </td>
      </tr>

      <tr>

        <td width="75%" valign="top">
        <p>

          <papertitle><a href="https://github.com/pvskand/HybridImages-Collage">Creating Collage using Hybrid Images</a></papertitle>  (August, 2017)

          <br>
          Mentor : <a href="https://sites.google.com/site/dhallabhinav/">Dr. Abhinav Dhall </a>, Dept. of CS, IIT Ropar, India
        <p>
          In this I used the concept of Hybrid images as presented in <i> Olivia et.al, SIGGRAPH 06</i> to create collages. After applying the hybrid image technique the images were blended to show smooth transition from one to the other. Detailed information can be found in <a href="pdf/hybrid.pdf"> this</a> report.

        </p>
        </p>
        </td>
      </tr>

      <tr>

        <td width="75%" valign="top">
        <p>

          <papertitle> <a href="https://github.com/pvskand/VisualBag-Homogaphy">Visual Bag of Words & Homography Estimation </a></papertitle>  (August, 2017)

          <br>
          Mentor : <a href="https://sites.google.com/site/dhallabhinav/">Dr. Abhinav Dhall </a>, Dept. of CS, IIT Ropar, India
        <p>
          Visual bag of words on the <a href="https://github.com/zalandoresearch/fashion-mnist"> Fashion MNIST </a> data set was implemented using k-means clustering. Also Mosaic was created using homography estimation(projective transformation), warping and then blending of the images. The technical report of this can be found <a href="pdf/bow.pdf"> here </a>.

        </p>
        </p>
        </td>
      </tr>


      </table>
      <table  width="100%" align="center" border="0" cellpadding="20">
      <h3>Digital Image Processing</h3>
        <tr>

        <td width="75%" valign="top">
        <p>

          <papertitle><a href="https://github.com/pvskand/ImageMorphing">Image Morphing </a></papertitle>  (Aug-Nov, 2016)

          <br>
          Mentor : <a href="http://www.iitrpr.ac.in/cse/puneet">Dr. Puneet Goyal </a>, Dept. of CS, IIT Ropar, India
        <p>
          We morphed 2 images by using Delaunay Triangulation technique. We take the tie points as input from the user and then compute the affine transformation from one image to the other and then blend the two images to get a smooth transition from one image to the other. This process can be perfomed with multiple images (we have performed it with 2 and 3 images).
        </p>
        </p>
        </td>
      </tr>
      </table>
      <table  width="100%" align="center" border="0" cellpadding="20">
      <h3>Software Engineering</h3>
        <tr>

        <td width="75%" valign="top">
        <p>

          <papertitle><a href="https://github.com/pvskand/addictionRemoval">Addiction Removal Application</a> </papertitle>  (Aug-Nov, 2017) <i> [Course Final Project]</i>

          <br>
          Mentor : <a href="http://www.iitrpr.ac.in/sodhi/">Dr. Balwinder Sodhi </a>, Dept. of CS, IIT Ropar, India
        <p>
          Addiction Removal is a platform for addicts to get rid of their addiction with help of other people who have already got rid of their addictions. Go ahead, find your mentor and read the motivating blogs. The development of the software is present in <a href="https://sites.google.com/a/iitrpr.ac.in/addiction-removal/home?pli=1">this</a> google site.
        </p>
        </p>
        </td>
      </tr>
      </table>

     <!--  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Teaching</heading>
        </td>
      </tr>
      </table> -->



      <!-- <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><img src="pacman.jpg" alt="pacman" width="160" height="160"></td>
        <td width="75%" valign="center">
        <p>
          <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">
          <papertitle>CS188 - Fall 2010 (GSI)</papertitle>
          </a>
          <br><br>
          <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">
          <papertitle>CS188 - Spring 2011 (GSI)</papertitle>
          </a>
          <br>
        </p>
        </td>
      </tr>
      </table> -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">

          Template : <a href="http://jeffdonahue.com/">this</a>, <a href="https://jonbarron.info/">this</a>, <a href="http://people.eecs.berkeley.edu/~pathak/">this</a> and <a href="https://people.eecs.berkeley.edu/~sgupta/">this</a>
          <!--http://changyeobshin.com/, https://mbanani.github.io/, https://aseembits93.github.io, http://fuwei.us/, https://people.eecs.berkeley.edu/~haarnoja/, http://ishshah.me/, http://web.stanford.edu/~sfort1/-->
	    </font>
        </p>
        </td>
      </tr>
      </table>

    </td>
    </tr>
  </table>


</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('cvprw18_abs');
hideblock('acmmm18_abs');
hideblock('miccai_abs');
</script>




  </body>
</html>
